apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "splunk-kubernetes-logging.fullname" . }}
  labels:
    app: {{ template "splunk-kubernetes-logging.name" . }}
    chart: {{ template "splunk-kubernetes-logging.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  fluent.conf: |-
    @include system.conf
    @include source.containers.conf
    @include source.files.conf
    @include source.journald.conf
    @include monit.conf
    @include output.conf
    {{- if .Values.global.prometheus_enabled }}
    @include prometheus.conf
    {{- end }}

  system.conf: |-
    # system wide configurations
    <system>
      log_level {{ or .Values.logLevel .Values.global.logLevel }}
      root_dir /tmp/fluentd
    </system>

  {{- if .Values.global.prometheus_enabled }}
  prometheus.conf: |-
    # input plugin that exports metrics
    <source>
      @type prometheus
    </source>

    <source>
      @type forward
    </source>

    # input plugin that collects metrics from MonitorAgent
    <source>
      @type prometheus_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>

    # input plugin that collects metrics for output plugin
    <source>
      @type prometheus_output_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
  {{- end }}

  source.containers.conf: |-
    # This configuration file for Fluentd / td-agent is used
    # to watch changes to Docker log files. The kubelet creates symlinks that
    # capture the pod name, namespace, container name & Docker container ID
    # to the docker logs for pods in the /var/log/containers directory on the host.
    # If running this fluentd configuration in a Docker container, the /var/log
    # directory should be mounted in the container.
    # reading kubelet logs from journal
    #
    # Reference:
    # https://github.com/kubernetes/community/blob/20d2f6f5498a5668bae2aea9dcaf4875b9c06ccb/contributors/design-proposals/node/kubelet-cri-logging.md
    #
    # Json Log Example:
    # {"log":"[info:2016-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2016-02-17T00:04:05.931087621Z"}
    # CRI Log Example (not supported):
    # 2016-02-17T00:04:05.931087621Z stdout [info:2016-02-16T16:04:05.930-08:00] Some log text here
    <source>
      @id containers.log
      @type tail
      @label @CONCAT
      tag tail.containers.*
      path {{ .Values.fluentd.path | default "/var/log/containers/*.log" }}
      {{- if .Values.fluentd.exclude_path }}
      exclude_path {{ .Values.fluentd.exclude_path | toJson }}
      {{- end }}
      pos_file /var/log/splunk-fluentd-containers.log.pos
      path_key source
      read_from_head true
      <parse>
      {{- if eq .Values.containers.logFormatType "cri" }}
        @type regexp
        expression /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
        time_format  {{ .Values.containers.logFormat | default "%Y-%m-%dT%H:%M:%S.%N%:z" }}
      {{- else if eq .Values.containers.logFormatType "json" }}
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      {{- end }}
        time_key time
        time_type string
        localtime false
      </parse>
    </source>

  source.files.conf: |-
    # This fluentd conf file contains sources for log files other than container logs.
    {{- $checks := dict "hasFileLog" false }}
    {{- range $name, $logDef := .Values.logs }}
    {{- if $logDef.from.file }}
    {{- set $checks "hasFileLog" true | and nil }}
    <source>
      @id tail.file.{{ $name }}
      @type tail
      @label @CONCAT
      tag tail.file.{{ or $logDef.sourcetype $name }}
      path {{ $logDef.from.file.path }}
      pos_file /var/log/splunk-fluentd-{{ $name }}.pos
      read_from_head true
      path_key source
      {{- if $logDef.multiline }}
      multiline_flush_interval {{ $logDef.multiline.flushInterval | default "5s" }}
      {{- end }}
      <parse>
        {{- if $logDef.multiline }}
        @type multiline
        format_firstline {{ $logDef.multiline.firstline }}
        {{- if $logDef.timestampExtraction }}
        format1 /^(?<log>{{ $logDef.timestampExtraction.regexp }}.*)$/
        time_key time
        time_type string
        time_format {{ $logDef.timestampExtraction.format }}
        {{- end }}
        {{- else if $logDef.timestampExtraction }}
        @type regexp
        expression /^(?<log>{{ $logDef.timestampExtraction.regexp }}.*)$/
        time_key time
        time_type string
        time_format {{ $logDef.timestampExtraction.format }}
        {{- else }}
        @type none
        message_key log
        {{- end }}
      </parse>
    </source>
    {{- end }}
    {{- end }}


  source.journald.conf: |-
    # This fluentd conf file contains configurations for reading logs from systemd journal.
    {{- range $name, $logDef := .Values.logs }}
    {{- if $logDef.from.journald }}
    {{- set $checks "hasJournald" true | and nil }}
    <source>
      @id journald-{{ $name }}
      @type systemd
      @label @CONCAT
      tag journald.{{ or $logDef.sourcetype $name }}
      path {{ $.Values.journalLogPath | quote }}
      matches [{ "_SYSTEMD_UNIT": {{ $logDef.from.journald.unit | quote }} }]
      read_from_head true
      <storage>
        @type local
        persistent true
        path /var/log/splunkd-fluentd-journald-{{ $name }}.pos.json
      </storage>
      <entry>
        field_map {"MESSAGE": "log", "_SYSTEMD_UNIT": "source"}
        field_map_strict true
      </entry>
    </source>
    {{- end }}
    {{- end }}


  monit.conf: |-
    <source>
      @id fluentd-monitor-agent
      @type monitor_agent
      @label @SPLUNK
      tag monitor_agent
    </source>


  output.conf: |-
    #Events are emitted to the CONCAT label from the container, file and journald sources for multiline processing.
    <label @CONCAT>
      # = filters for container logs =
      {{- range $name, $logDef := .Values.logs }}
      {{- if and $logDef.from.pod $logDef.multiline }}
      <filter tail.containers.var.log.containers.{{ $logDef.from.pod }}*{{ or $logDef.from.container $name }}*.log>
        @type concat
        key log
        timeout_label @SPLUNK
        stream_identity_key stream
        multiline_start_regexp {{ $logDef.multiline.firstline }}
        flush_interval {{ $logDef.multiline.flushInterval | default "5s" }}
        separator {{ $logDef.multiline.separator | default "" | quote }}
        use_first_timestamp true
      </filter>
      {{- end }}
      {{- end }}
      # = filters for journald logs =
      {{- range $name, $logDef := .Values.logs }}
      {{- if and $logDef.from.journald $logDef.multiline }}
      <filter journald.{{ or $logDef.sourcetype $name }}>
        @type concat
        key log
        timeout_label @SPLUNK
        multiline_start_regexp {{ $logDef.multiline.firstline }}
        flush_interval {{ $logDef.multiline.flushInterval | default "5s" }}
      </filter>
      {{- end }}
      {{- end }}
      # Events are relabeled then emitted to the SPLUNK label
      <match **>
        @type relabel
        @label @SPLUNK
      </match>
    </label>
    <label @SPLUNK>
      # Enrich log with k8s metadata
      <filter tail.containers.**>
        @type kubernetes_metadata
        annotation_match [ "^splunk\.com" ]
        de_dot false
      </filter>
      <filter tail.containers.**>
        @type record_transformer
        enable_ruby
        <record>
          # set the sourcetype from splunk.com/sourcetype pod annotation or set it to kube:container:CONTAINER_NAME
          sourcetype ${record.dig("kubernetes", "annotations", "splunk.com/sourcetype") ? "kube:"+record.dig("kubernetes", "annotations", "splunk.com/sourcetype") : "kube:container:"+record.dig("kubernetes","container_name")}
          container_name ${record.dig("kubernetes","container_name")}
          namespace ${record.dig("kubernetes","namespace_name")}
          pod ${record.dig("kubernetes","pod_name")}
          container_id ${record.dig("docker","container_id")}
          pod_uid ${record.dig("kubernetes","pod_id")}
          container_image ${record.dig("kubernetes","container_image")}
          # set the cluster_name field to the configured value, or default to "cluster_name"
          {{- with or .Values.kubernetes.clusterName .Values.global.kubernetes.clusterName | default "cluster_name" }}
          cluster_name {{ . }}
          {{- end }}
          # set the index field to the value found in the pod splunk.com/index annotations. if not set, use namespace annotation, or default to the default_index
          index ${record.dig("kubernetes", "annotations", "splunk.com/index") ? record.dig("kubernetes", "annotations", "splunk.com/index") : record.dig("kubernetes", "namespace_annotations", "splunk.com/index") ? (record["kubernetes"]["namespace_annotations"]["splunk.com/index"]) : ("{{ or .Values.splunk.hec.indexName .Values.global.splunk.hec.indexName | default "main"}}")}
          {{- range .Values.k8sMetadata.podLabels }}
          label_{{ . }} ${record.dig("kubernetes","labels","{{ . }}")}
          {{- end }}
          blacklist ${record.dig("kubernetes", "annotations", "splunk.com/exclude") ? record.dig("kubernetes", "annotations", "splunk.com/exclude") : record.dig("kubernetes", "namespace_annotations", "splunk.com/exclude") ? (record["kubernetes"]["namespace_annotations"]["splunk.com/exclude"]) : ("false")}
          {{- if .Values.customMetadata }}
          {{- range .Values.customMetadata }}
          {{ .name }} "{{ .value }}"
          {{- end }}
          {{- end }}
        </record>
      </filter>
      <filter tail.containers.**>
        # Exclude all logs that are blacklisted
        @type grep
        <exclude>
          key blacklist
          pattern /^true$/
        </exclude>
      </filter>
      # extract pod_uid and container_name for CRIO runtime
      {{- if eq .Values.containers.logFormatType "cri" }}
      <filter tail.containers.var.log.pods.**>
        @type jq_transformer
        jq '.record | . + (.source | capture("/var/log/pods/(?<pod_uid>[^/]+)/(?<container_name>[^/]+)/(?<container_retry>[0-9]+).log")) | .sourcetype = ("kube:container:" + .container_name) | .index = {{ or .Values.global.splunk.hec.indexName .Values.splunk.hec.indexName | default "main" | quote }}'
      </filter>
      {{- end }}

      # create source and sourcetype
      {{- if $checks.hasJournald }}
      <filter journald.**>
        @type jq_transformer
        jq '.record.source = "{{ .Values.journalLogPath }}/" + .record.source | .record.sourcetype = (.tag | ltrimstr("journald.")) | .record.cluster_name = "{{ or .Values.kubernetes.clusterName .Values.global.kubernetes.clusterName | default "cluster_name" }}" | .record.index = {{ or .Values.global.splunk.hec.indexName .Values.splunk.hec.indexName | default "main" | quote }} {{- if .Values.customMetadata }}{{- range .Values.customMetadata }}| .record.{{ .name }} = "{{ .value }}" {{- end }}{{- end }} |.record'
      </filter>
      {{- end }}

      # = filters for non-container log files =
      {{- if $checks.hasFileLog }}
      # extract sourcetype
      <filter tail.file.**>
        @type jq_transformer
        jq '.record.sourcetype = (.tag | ltrimstr("tail.file.")) | .record.cluster_name = "{{ or .Values.kubernetes.clusterName .Values.global.kubernetes.clusterName | default "cluster_name" }}" | .record.index = {{ or .Values.global.splunk.hec.indexName .Values.splunk.hec.indexName | default "main" | quote }} {{- if .Values.customMetadata }}{{- range .Values.customMetadata }}| .record.{{ .name }} = "{{ .value }}" {{- end }}{{- end }} | .record'
      </filter>
      {{- end }}

      # = filters for monitor agent =
      <filter monitor_agent>
        @type jq_transformer
        jq ".record.source = \"namespace:#{ENV['MY_NAMESPACE']}/pod:#{ENV['MY_POD_NAME']}\" | .record.sourcetype = \"fluentd:monitor-agent\" | .record.cluster_name = \"{{ or .Values.kubernetes.clusterName .Values.global.kubernetes.clusterName | default "cluster_name" }}\" | .record.index = \"{{ or .Values.global.splunk.hec.indexName .Values.splunk.hec.indexName | default "main" }}\" {{- if .Values.customMetadata }}{{- range .Values.customMetadata }}| .record.{{ .name }} = \"{{ .value }}\" {{- end }}{{- end }} | .record"
      </filter>

      # = custom filters specified by users =
      {{- range $name, $filterDef := .Values.customFilters }}
      {{- if and $filterDef.tag $filterDef.type }}
      <filter {{ $filterDef.tag }}>
        @type {{ $filterDef.type }}
        {{- if $filterDef.body }}
        {{ $filterDef.body | indent 8 }}
        {{- end }}
      </filter>
      {{- end }}
      {{- end }}

      # = output =
      <match **>
        {{- if or .Values.splunk.hec.host .Values.global.splunk.hec.host }}
        @type splunk_hec
        {{- with or .Values.splunk.hec.protocol .Values.global.splunk.hec.protocol }}
        protocol {{ . }}
        {{- end }}
        {{- with or .Values.splunk.hec.host .Values.global.splunk.hec.host }}
        hec_host {{ . | quote }}
        {{- end }}
        {{- with or .Values.splunk.hec.port .Values.global.splunk.hec.port }}
        hec_port {{ . }}
        {{- end }}
        hec_token "#{ENV['SPLUNK_HEC_TOKEN']}"
        index_key index
        insecure_ssl {{ or .Values.splunk.hec.insecureSSL .Values.global.splunk.hec.insecureSSL | default false }}
        {{- if or .Values.splunk.hec.clientCert .Values.global.splunk.hec.clientCert }}
        client_cert /fluentd/etc/splunk/hec_client_cert
        {{- end }}
        {{- if or .Values.splunk.hec.clientKey .Values.global.splunk.hec.clientKey }}
        client_key /fluentd/etc/splunk/hec_client_key
        {{- end }}
        {{- if or .Values.splunk.hec.caFile .Values.global.splunk.hec.caFile }}
        ca_file /fluentd/etc/splunk/hec_ca_file
        {{- end }}
        {{- else }}
        @type splunk_ingest_api
        {{- with or .Values.splunk.ingest_api.serviceClientIdentifier }}
        service_client_identifier {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.serviceClientSecretKey }}
        service_client_secret_key {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.tokenEndpoint }}
        token_endpoint {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.ingestAuthHost }}
        ingest_auth_host {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.ingestAPIHost }}
        ingest_api_host {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.tenant }}
        ingest_api_tenant {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.eventsEndpoint }}
        ingest_api_events_endpoint {{ . }}
        {{- end }}
        {{- with or .Values.splunk.ingest_api.debugIngestAPI }}
        debug_http {{ . }}
        {{- end }}
        {{- end }}
        host "#{ENV['K8S_NODE_NAME']}"
        source_key source
        sourcetype_key sourcetype
        <fields>
          # currently CRI does not produce log paths with all the necessary
          # metadata to parse out pod, namespace, container_name, container_id.
          # this may be resolved in the future by this issue: https://github.com/kubernetes/kubernetes/issues/58638#issuecomment-385126031
          {{- if eq .Values.containers.logFormatType "cri"}}
          container_retry
          {{- else }}
          container_image
          {{- end }}
          pod_uid
          pod
          container_name
          namespace
          container_id
          {{- if or .Values.kubernetes.clusterName .Values.global.kubernetes.clusterName }}
          cluster_name
          {{- end }}
          {{- if .Values.customMetadata }}
          {{- range .Values.customMetadata }}
          {{ .name }}
          {{- end }}
          {{- end }}
          {{- range .Values.indexFields }}
          {{ . }}
          {{- end }}
          {{- range .Values.k8sMetadata.podLabels }}
          label_{{ . }}
          {{- end }}
        </fields>
        {{- with .Values.buffer }}
        <buffer>
        {{- range $parameter, $value := . }}
          {{ $parameter }} {{ $value }}
        {{- end }}
        </buffer>
        {{- end }}
        <format monitor_agent>
          @type json
        </format>
        <format>
          # we just want to keep the raw logs, not the structure created by docker or journald
          @type single_value
          message_key log
          add_newline false
        </format>
      </match>
    </label>
